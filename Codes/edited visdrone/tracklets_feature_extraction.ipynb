{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracklets for uav0000289_00001_v-1.txt -> F:\\edited visdrone\\tracklets\\uav0000289_00001_v-1-tracklets.txt\n",
      "Saved tracklets for uav0000308_00000_v-1.txt -> F:\\edited visdrone\\tracklets\\uav0000308_00000_v-1-tracklets.txt\n",
      "Saved tracklets for uav0000323_01173_v-1.txt -> F:\\edited visdrone\\tracklets\\uav0000323_01173_v-1-tracklets.txt\n",
      "Saved tracklets for uav0000326_01035_v-1.txt -> F:\\edited visdrone\\tracklets\\uav0000326_01035_v-1-tracklets.txt\n",
      "Saved tracklets for uav0000329_04715_v-1.txt -> F:\\edited visdrone\\tracklets\\uav0000329_04715_v-1-tracklets.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_tracklets(annotation_file, max_gap=3):\n",
    "    \"\"\"\n",
    "    Creates tracklets from the given annotation file by grouping consecutive detections of the same object.\n",
    "\n",
    "    Args:\n",
    "    - annotation_file (str): Path to the annotation text file.\n",
    "    - max_gap (int): Maximum gap allowed before creating a new tracklet.\n",
    "\n",
    "    Returns:\n",
    "    - tracklets (dict): Dictionary where keys are tracklet IDs and values are lists of (frame_id, object_id, x, y, width, height, score, class, visibility).\n",
    "    \"\"\"\n",
    "\n",
    "    object_tracks = defaultdict(list)  # Stores all detections per object_id\n",
    "    tracklets = {}  # Stores fragmented tracklets\n",
    "    tracklet_id = 0  # Unique tracklet identifier\n",
    "\n",
    "    # Read annotation file\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                frame_id, object_id, x, y, width, height, score, obj_class, visibility, ignored = map(float, row)\n",
    "                object_id = int(object_id)\n",
    "                frame_id = int(frame_id)\n",
    "\n",
    "                object_tracks[object_id].append((frame_id, object_id, x, y, width, height, score, obj_class, visibility))\n",
    "\n",
    "            except ValueError:\n",
    "                print(f\"Skipping malformed line: {row}\")\n",
    "\n",
    "    # Create tracklets by detecting gaps in object tracking\n",
    "    for obj_id, detections in object_tracks.items():\n",
    "        detections.sort()  # Ensure detections are sorted by frame_id\n",
    "\n",
    "        last_frame = -1\n",
    "        current_tracklet = []\n",
    "\n",
    "        for detection in detections:\n",
    "            frame_id = detection[0]\n",
    "\n",
    "            if last_frame != -1 and (frame_id - last_frame) > max_gap:\n",
    "                # Start a new tracklet if gap is too large\n",
    "                tracklets[tracklet_id] = current_tracklet\n",
    "                tracklet_id += 1\n",
    "                current_tracklet = []\n",
    "\n",
    "            current_tracklet.append(detection)\n",
    "            last_frame = frame_id\n",
    "\n",
    "        # Store remaining tracklet\n",
    "        if current_tracklet:\n",
    "            tracklets[tracklet_id] = current_tracklet\n",
    "            tracklet_id += 1\n",
    "\n",
    "    return tracklets\n",
    "\n",
    "def process_all_files(annotation_folder, output_folder, max_gap=3):\n",
    "    \"\"\"\n",
    "    Processes all annotation files in a folder and saves tracklets for each file.\n",
    "\n",
    "    Args:\n",
    "    - annotation_folder (str): Folder containing annotation files.\n",
    "    - output_folder (str): Folder to save tracklet files.\n",
    "    - max_gap (int): Maximum gap allowed before creating a new tracklet.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file in os.listdir(annotation_folder):\n",
    "        if file.endswith(\".txt\"):  # Process only text files\n",
    "            annotation_file = os.path.join(annotation_folder, file)\n",
    "            tracklets = create_tracklets(annotation_file, max_gap)\n",
    "\n",
    "            output_file = os.path.join(output_folder, file.replace(\".txt\", \"-tracklets.txt\"))\n",
    "\n",
    "            # Save tracklets\n",
    "            with open(output_file, \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                for tracklet_id, frames in tracklets.items():\n",
    "                    for frame in frames:\n",
    "                        writer.writerow([tracklet_id] + list(frame))\n",
    "\n",
    "            print(f\"Saved tracklets for {file} -> {output_file}\")\n",
    "\n",
    "# Example Usage\n",
    "annotation_folder = r\"F:\\edited visdrone\\annotations\"\n",
    "output_folder = r\"F:\\edited visdrone\\tracklets\"\n",
    "process_all_files(annotation_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to F:\\edited visdrone\\processed_tracklets\\uav0000289_00001_v-1-tracklets.txt\n",
      "Metrics saved to F:\\edited visdrone\\processed_tracklets\\uav0000308_00000_v-1-tracklets.txt\n",
      "Metrics saved to F:\\edited visdrone\\processed_tracklets\\uav0000323_01173_v-1-tracklets.txt\n",
      "Metrics saved to F:\\edited visdrone\\processed_tracklets\\uav0000326_01035_v-1-tracklets.txt\n",
      "Metrics saved to F:\\edited visdrone\\processed_tracklets\\uav0000329_04715_v-1-tracklets.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_tracklet_metrics(tracklets_folder, output_folder):\n",
    "    tracklet_files = glob.glob(os.path.join(tracklets_folder, \"*.txt\"))\n",
    "\n",
    "    if not tracklet_files:\n",
    "        print(\"No tracklet files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "\n",
    "    for file_path in tracklet_files:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        if not lines:\n",
    "            print(f\"Warning: {file_path} is empty.\")\n",
    "            continue\n",
    "\n",
    "        tracklet_data = defaultdict(list)\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) < 10:\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            tracklet_id = int(parts[0])  # Unique tracklet ID\n",
    "            frame_id = int(parts[1])     # Frame number\n",
    "            x, y = float(parts[3]), float(parts[4])  # Ignore parts[2], use parts[3] and parts[4]\n",
    "            width, height = float(parts[5]), float(parts[6])\n",
    "\n",
    "            tracklet_data[tracklet_id].append((frame_id, x, y, width, height))\n",
    "\n",
    "        output_file_path = os.path.join(output_folder, os.path.basename(file_path))\n",
    "\n",
    "        with open(output_file_path, \"w\") as f_out:\n",
    "            for tracklet_id, data in tracklet_data.items():\n",
    "                if len(data) < 2:\n",
    "                    print(f\"Skipping Tracklet {tracklet_id} in {file_path} (not enough frames to compute velocity).\")\n",
    "                    continue\n",
    "\n",
    "                data.sort()  # Sort by frame_id\n",
    "\n",
    "                velocities = []\n",
    "                areas = []\n",
    "                aspect_ratios = []\n",
    "\n",
    "                for i in range(1, len(data)):\n",
    "                    prev_frame, prev_x, prev_y, _, _ = data[i - 1]\n",
    "                    curr_frame, curr_x, curr_y, width, height = data[i]\n",
    "\n",
    "                    # Compute velocity (Euclidean distance per frame difference)\n",
    "                    frame_diff = curr_frame - prev_frame\n",
    "                    if frame_diff > 0:\n",
    "                        velocity = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2) / frame_diff\n",
    "                        velocities.append(velocity)\n",
    "\n",
    "                    # Compute bounding box area\n",
    "                    area = width * height\n",
    "                    areas.append(area)\n",
    "\n",
    "                    # Compute aspect ratio\n",
    "                    aspect_ratio = width / height if height > 0 else 0\n",
    "                    aspect_ratios.append(aspect_ratio)\n",
    "\n",
    "                avg_velocity = np.mean(velocities) if velocities else 0\n",
    "                avg_area = np.mean(areas) if areas else 0\n",
    "                avg_aspect_ratio = np.mean(aspect_ratios) if aspect_ratios else 0\n",
    "\n",
    "                # Write to file in CSV format: Tracklet ID, Avg Velocity, Avg Area, Avg Aspect Ratio\n",
    "                f_out.write(f\"{tracklet_id},{avg_velocity:.3f},{avg_area:.3f},{avg_aspect_ratio:.3f}\\n\")\n",
    "\n",
    "        print(f\"Metrics saved to {output_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "tracklets_folder = r\"F:\\edited visdrone\\tracklets\"  # Change this to your input folder path\n",
    "output_folder = r\"F:\\edited visdrone\\processed_tracklets\"  # Change this to your output folder path\n",
    "compute_tracklet_metrics(tracklets_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to F:\\edited visdrone\\sift_and_histogram\\uav0000289_00001_v-1-tracklets.txt\n",
      "Features saved to F:\\edited visdrone\\sift_and_histogram\\uav0000308_00000_v-1-tracklets.txt\n",
      "Features saved to F:\\edited visdrone\\sift_and_histogram\\uav0000323_01173_v-1-tracklets.txt\n",
      "Features saved to F:\\edited visdrone\\sift_and_histogram\\uav0000326_01035_v-1-tracklets.txt\n",
      "Features saved to F:\\edited visdrone\\sift_and_histogram\\uav0000329_04715_v-1-tracklets.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_color_histogram(image, bbox):\n",
    "    \"\"\"\n",
    "    Computes the average color histogram for a given bounding box in an image.\n",
    "\n",
    "    Args:\n",
    "    - image (np.array): Input image.\n",
    "    - bbox (tuple): (x, y, width, height) of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - hist (np.array): Flattened color histogram (normalized).\n",
    "    \"\"\"\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = image[y:y+h, x:x+w]  # Crop the bounding box\n",
    "\n",
    "    if roi.size == 0:\n",
    "        return np.zeros((512,))  # Return zero histogram if region is invalid\n",
    "\n",
    "    hist = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()  # Normalize and flatten\n",
    "    return hist\n",
    "\n",
    "def compute_sift_descriptors(image, bbox):\n",
    "    \"\"\"\n",
    "    Computes the average SIFT descriptor for a given bounding box in an image.\n",
    "\n",
    "    Args:\n",
    "    - image (np.array): Input image.\n",
    "    - bbox (tuple): (x, y, width, height) of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - avg_descriptor (np.array): Mean SIFT descriptor (128D) or zero vector if none found.\n",
    "    \"\"\"\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = image[y:y+h, x:x+w]  # Crop the bounding box\n",
    "\n",
    "    if roi.size == 0:\n",
    "        return np.zeros((128,))  # Return zero descriptor if region is invalid\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(roi, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        return np.zeros((128,))  # Return zero descriptor if no keypoints found\n",
    "\n",
    "    return np.mean(descriptors, axis=0)  # Compute average descriptor\n",
    "\n",
    "def process_tracklet_features(tracklets_folder, frames_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Computes the average color histogram and SIFT descriptor for each tracklet.\n",
    "\n",
    "    Args:\n",
    "    - tracklets_folder (str): Folder containing tracklet annotation files.\n",
    "    - frames_folder (str): Folder containing image sequences.\n",
    "    - output_folder (str): Folder to save the extracted features.\n",
    "    \"\"\"\n",
    "    tracklet_files = glob.glob(os.path.join(tracklets_folder, \"*.txt\"))\n",
    "\n",
    "    if not tracklet_files:\n",
    "        print(\"No tracklet files found in the folder.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "\n",
    "    for file_path in tracklet_files:\n",
    "        tracklet_data = defaultdict(list)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        if not lines:\n",
    "            print(f\"Warning: {file_path} is empty.\")\n",
    "            continue\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(\",\")\n",
    "            if len(parts) < 10:\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            tracklet_id = int(parts[0])  # Unique tracklet ID\n",
    "            frame_id = int(parts[1])     # Frame number\n",
    "            x, y, width, height = map(float, parts[3:7])\n",
    "\n",
    "            tracklet_data[tracklet_id].append((frame_id, x, y, width, height))\n",
    "\n",
    "        # Determine the sequence folder from filename (assuming folder names match video names)\n",
    "        video_name = os.path.basename(file_path).replace(\"-1-tracklets.txt\", \"\")\n",
    "        sequence_folder = os.path.join(frames_folder, video_name)\n",
    "\n",
    "        if not os.path.exists(sequence_folder):\n",
    "            print(f\"Warning: Missing sequence folder {sequence_folder}. Skipping file {file_path}.\")\n",
    "            continue\n",
    "\n",
    "        output_file_path = os.path.join(output_folder, os.path.basename(file_path))\n",
    "\n",
    "        with open(output_file_path, \"w\") as f_out:\n",
    "            for tracklet_id, bboxes in tracklet_data.items():\n",
    "                color_histograms = []\n",
    "                sift_descriptors = []\n",
    "\n",
    "                for frame_id, x, y, w, h in bboxes:\n",
    "                    image_path = os.path.join(sequence_folder, f\"{frame_id:07d}.jpg\")  # Assumes 7-digit frame filenames\n",
    "\n",
    "                    if not os.path.exists(image_path):\n",
    "                        continue  # Skip missing frames\n",
    "\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is None:\n",
    "                        continue  # Skip corrupted images\n",
    "\n",
    "                    hist = compute_color_histogram(image, (x, y, w, h))\n",
    "                    sift_desc = compute_sift_descriptors(image, (x, y, w, h))\n",
    "\n",
    "                    color_histograms.append(hist)\n",
    "                    sift_descriptors.append(sift_desc)\n",
    "\n",
    "                if not color_histograms or not sift_descriptors:\n",
    "                    print(f\"Skipping Tracklet {tracklet_id} in {file_path} (no valid images).\")\n",
    "                    continue\n",
    "\n",
    "                avg_histogram = np.mean(color_histograms, axis=0)\n",
    "                avg_sift_descriptor = np.mean(sift_descriptors, axis=0)\n",
    "\n",
    "                # Save as CSV format: tracklet_id, histogram values, sift descriptor values\n",
    "                hist_str = \",\".join(map(str, avg_histogram))\n",
    "                sift_str = \",\".join(map(str, avg_sift_descriptor))\n",
    "\n",
    "                f_out.write(f\"{tracklet_id},{hist_str},{sift_str}\\n\")\n",
    "\n",
    "        print(f\"Features saved to {output_file_path}\")\n",
    "\n",
    "# Example Usage\n",
    "tracklets_folder = r\"F:\\edited visdrone\\tracklets\"  # Change this to your tracklet folder\n",
    "frames_folder = r\"F:\\edited visdrone\\sequences\"  # Change this to your image sequence folder\n",
    "output_folder = r\"F:\\edited visdrone\\sift_and_histogram\"  # Change this to your output folder\n",
    "process_tracklet_features(tracklets_folder, frames_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
