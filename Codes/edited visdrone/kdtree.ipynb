{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 4 tracklets from F:\\edited visdrone\\tracklets\n",
      "âœ… Loaded 4 tracklet statistics from F:\\edited visdrone\\processed_tracklets\n",
      "âœ… Loaded 4 visual features from F:\\edited visdrone\\sift_and_histogram\n",
      "âœ… Constructed feature matrix with 4 entries.\n",
      "ðŸ”„ Iteration 1: 4 tracklets remaining.\n",
      "âœ… Found 4 merging tracklet pairs.\n",
      "âœ… Constructed feature matrix with 2 entries.\n",
      "ðŸ”„ Iteration 2: 2 tracklets remaining.\n",
      "âœ… Found 2 merging tracklet pairs.\n",
      "âœ… Constructed feature matrix with 1 entries.\n",
      "âœ… Interpolated missing info for 1 tracklets.\n",
      "âœ… Processed and saved 1 merged tracklets in: F:\\edited visdrone\\merged_tracklets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_tracklet_data(tracklet_folder):\n",
    "    \"\"\"Load per-frame tracklet data.\"\"\"\n",
    "    tracklets = {}\n",
    "    for file in os.listdir(tracklet_folder):\n",
    "        file_path = os.path.join(tracklet_folder, file)\n",
    "        if file.endswith(\".txt\"):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            for _, row in df.iterrows():\n",
    "                tracklet_id = row[0]  # Tracklet ID\n",
    "                features = row[1:].tolist()  # Other features\n",
    "                if tracklet_id not in tracklets:\n",
    "                    tracklets[tracklet_id] = []\n",
    "                tracklets[tracklet_id].append(features)\n",
    "\n",
    "    print(f\"âœ… Loaded {len(tracklets)} tracklets from {tracklet_folder}\")\n",
    "    return tracklets\n",
    "\n",
    "def load_statistics(stats_folder):\n",
    "    \"\"\"Load tracklet statistics (Velocity, Area, Aspect Ratio).\"\"\"\n",
    "    stats = {}\n",
    "    for file in os.listdir(stats_folder):\n",
    "        file_path = os.path.join(stats_folder, file)\n",
    "        if file.endswith(\".txt\"):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            for _, row in df.iterrows():\n",
    "                tracklet_id = row[0]\n",
    "                stats[tracklet_id] = row[1:].tolist()  # Avg Velocity, Area, Aspect Ratio\n",
    "\n",
    "    print(f\"âœ… Loaded {len(stats)} tracklet statistics from {stats_folder}\")\n",
    "    return stats\n",
    "\n",
    "def load_visual_features(feature_folder):\n",
    "    \"\"\"Load visual features (Color Histogram + SIFT).\"\"\"\n",
    "    visual_features = {}\n",
    "    for file in os.listdir(feature_folder):\n",
    "        file_path = os.path.join(feature_folder, file)\n",
    "        if file.endswith(\".txt\"):\n",
    "            df = pd.read_csv(file_path, header=None)\n",
    "            for _, row in df.iterrows():\n",
    "                tracklet_id = row[0]\n",
    "                hist = row[1:513].tolist()  # Color histogram (512 values)\n",
    "                sift = row[513:].tolist()  # SIFT descriptor (128 values)\n",
    "                visual_features[tracklet_id] = hist + sift  # Combine all features\n",
    "\n",
    "    print(f\"âœ… Loaded {len(visual_features)} visual features from {feature_folder}\")\n",
    "    return visual_features\n",
    "\n",
    "def construct_feature_matrix(tracklets, stats, visuals):\n",
    "    \"\"\"Construct a feature matrix combining all features.\"\"\"\n",
    "    feature_matrix = []\n",
    "    tracklet_ids = []\n",
    "\n",
    "    for tracklet_id in tracklets.keys():\n",
    "        position_features = np.mean(tracklets[tracklet_id], axis=0)  # Average frame features\n",
    "        stat_features = stats.get(tracklet_id, [0, 0, 0])  # Default 0 if missing\n",
    "        visual_features = visuals.get(tracklet_id, [0] * 640)  # Default 0 if missing\n",
    "\n",
    "        # Apply different weights to features\n",
    "        weighted_position = np.array(position_features) * 1.0  # Keep position as is\n",
    "        weighted_stats = np.array(stat_features) * 5.0  # Increase weight of velocity, area, etc.\n",
    "        weighted_visuals = np.array(visual_features) * 0.1  # Reduce weight of visual features\n",
    "\n",
    "        feature_vector = np.concatenate([weighted_position, weighted_stats, weighted_visuals])\n",
    "        feature_matrix.append(feature_vector)\n",
    "        tracklet_ids.append(tracklet_id)\n",
    "    \n",
    "    # Normalize features to ensure KD-Tree works correctly\n",
    "    scaler = StandardScaler()\n",
    "    feature_matrix = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "    print(f\"âœ… Constructed feature matrix with {len(feature_matrix)} entries.\")\n",
    "    return np.array(feature_matrix), tracklet_ids\n",
    "\n",
    "def merge_tracklets_with_kdtree(feature_matrix, tracklet_ids, tracklets):\n",
    "    \"\"\"Merge tracklets by always choosing the nearest neighbor.\"\"\"\n",
    "    tree = KDTree(feature_matrix)\n",
    "    merged_tracklets = {}\n",
    "\n",
    "    for i, tracklet_id in enumerate(tracklet_ids):\n",
    "        distances, indices = tree.query(feature_matrix[i], k=2)  # Get the closest neighbor\n",
    "        best_match_idx = indices[1]  # Second closest (first is itself)\n",
    "\n",
    "        best_match = tracklet_ids[best_match_idx]\n",
    "        merged_tracklets.setdefault(tracklet_id, set()).add(best_match)\n",
    "\n",
    "    print(f\"âœ… Found {len(merged_tracklets)} merging tracklet pairs.\")\n",
    "    return merged_tracklets\n",
    "\n",
    "def interpolate_missing_info(tracklets, merged_tracklets):\n",
    "    \"\"\"Fill missing information using interpolation.\"\"\"\n",
    "    filled_tracklets = defaultdict(list)\n",
    "\n",
    "    for tracklet_id, similar_ids in merged_tracklets.items():\n",
    "        all_data = []\n",
    "\n",
    "        for t_id in similar_ids:\n",
    "            if t_id in tracklets:\n",
    "                all_data.extend(tracklets[t_id])\n",
    "\n",
    "        if all_data:\n",
    "            filled_tracklets[tracklet_id] = np.mean(all_data, axis=0)  # Use mean for missing values\n",
    "\n",
    "    print(f\"âœ… Interpolated missing info for {len(filled_tracklets)} tracklets.\")\n",
    "    return filled_tracklets\n",
    "\n",
    "def iterative_tracklet_merging(tracklet_folder, stats_folder, feature_folder, output_folder):\n",
    "    \"\"\"Main function to process and iteratively merge tracklets.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    tracklets = load_tracklet_data(tracklet_folder)\n",
    "    stats = load_statistics(stats_folder)\n",
    "    visuals = load_visual_features(feature_folder)\n",
    "\n",
    "    # Construct feature matrix\n",
    "    feature_matrix, tracklet_ids = construct_feature_matrix(tracklets, stats, visuals)\n",
    "\n",
    "    # Iteratively merge tracklets in pairs\n",
    "    iteration = 1\n",
    "    while len(tracklet_ids) > 1:\n",
    "        print(f\"ðŸ”„ Iteration {iteration}: {len(tracklet_ids)} tracklets remaining.\")\n",
    "        merged_tracklets = merge_tracklets_with_kdtree(feature_matrix, tracklet_ids, tracklets)\n",
    "\n",
    "        if not merged_tracklets:  # If no pairs found, stop merging\n",
    "            break\n",
    "\n",
    "        # Merge closest pairs\n",
    "        merged = set()\n",
    "        for t1, t2_set in merged_tracklets.items():\n",
    "            for t2 in t2_set:\n",
    "                if t1 in tracklets and t2 in tracklets and t1 not in merged and t2 not in merged:\n",
    "                    tracklets[t1].extend(tracklets[t2])  # Merge tracklet data\n",
    "                    del tracklets[t2]  # Remove merged tracklet\n",
    "                    merged.add(t1)\n",
    "                    merged.add(t2)\n",
    "\n",
    "        # Rebuild feature matrix for next iteration\n",
    "        feature_matrix, tracklet_ids = construct_feature_matrix(tracklets, stats, visuals)\n",
    "        iteration += 1\n",
    "\n",
    "    # Fill missing info\n",
    "    filled_tracklets = interpolate_missing_info(tracklets, merged_tracklets)\n",
    "\n",
    "    # Save output\n",
    "    output_count = 0\n",
    "    for tracklet_id, features in filled_tracklets.items():\n",
    "        output_file = os.path.join(output_folder, f\"{tracklet_id}_merged.txt\")\n",
    "        np.savetxt(output_file, [features], delimiter=',', fmt=\"%.6f\")\n",
    "        output_count += 1\n",
    "\n",
    "    print(f\"âœ… Processed and saved {output_count} merged tracklets in: {output_folder}\")\n",
    "\n",
    "# Example Usage\n",
    "tracklet_folder = r\"F:\\edited visdrone\\tracklets\"\n",
    "stats_folder = r\"F:\\edited visdrone\\processed_tracklets\"\n",
    "feature_folder = r\"F:\\edited visdrone\\sift_and_histogram\"\n",
    "output_folder = r\"F:\\edited visdrone\\merged_tracklets\"\n",
    "\n",
    "iterative_tracklet_merging(tracklet_folder, stats_folder, feature_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
