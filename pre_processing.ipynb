{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0646adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sequence: uav0000013_00000_v\n",
      "Saved: preprocessed\\uav0000013_00000_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000013_01073_v\n",
      "Saved: preprocessed\\uav0000013_01073_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000013_01392_v\n",
      "Saved: preprocessed\\uav0000013_01392_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000020_00406_v\n",
      "Saved: preprocessed\\uav0000020_00406_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000071_03240_v\n",
      "Saved: preprocessed\\uav0000071_03240_v_processed.csv with 1375 entries.\n",
      "\n",
      "Processing sequence: uav0000072_04488_v\n",
      "Saved: preprocessed\\uav0000072_04488_v_processed.csv with 484 entries.\n",
      "\n",
      "Processing sequence: uav0000072_05448_v\n",
      "Saved: preprocessed\\uav0000072_05448_v_processed.csv with 1120 entries.\n",
      "\n",
      "Processing sequence: uav0000072_06432_v\n",
      "Saved: preprocessed\\uav0000072_06432_v_processed.csv with 855 entries.\n",
      "\n",
      "Processing sequence: uav0000076_00720_v\n",
      "Saved: preprocessed\\uav0000076_00720_v_processed.csv with 2021 entries.\n",
      "\n",
      "Processing sequence: uav0000079_00480_v\n",
      "Saved: preprocessed\\uav0000079_00480_v_processed.csv with 20 entries.\n",
      "\n",
      "Processing sequence: uav0000084_00000_v\n",
      "Saved: preprocessed\\uav0000084_00000_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000099_02109_v\n",
      "Saved: preprocessed\\uav0000099_02109_v_processed.csv with 0 entries.\n",
      "\n",
      "Processing sequence: uav0000124_00944_v\n",
      "Saved: preprocessed\\uav0000124_00944_v_processed.csv with 19553 entries.\n",
      "\n",
      "Processing sequence: uav0000126_00001_v\n",
      "Saved: preprocessed\\uav0000126_00001_v_processed.csv with 25276 entries.\n",
      "\n",
      "Processing sequence: uav0000138_00000_v\n",
      "Saved: preprocessed\\uav0000138_00000_v_processed.csv with 8866 entries.\n",
      "\n",
      "Processing sequence: uav0000140_01590_v\n",
      "Saved: preprocessed\\uav0000140_01590_v_processed.csv with 9150 entries.\n",
      "\n",
      "Processing sequence: uav0000143_02250_v\n",
      "Saved: preprocessed\\uav0000143_02250_v_processed.csv with 6108 entries.\n",
      "\n",
      "Processing sequence: uav0000145_00000_v\n",
      "Saved: preprocessed\\uav0000145_00000_v_processed.csv with 1588 entries.\n",
      "\n",
      "Processing sequence: uav0000150_02310_v\n",
      "Saved: preprocessed\\uav0000150_02310_v_processed.csv with 5268 entries.\n",
      "\n",
      "Processing sequence: uav0000218_00001_v\n",
      "Saved: preprocessed\\uav0000218_00001_v_processed.csv with 829 entries.\n",
      "\n",
      "Processing sequence: uav0000222_03150_v\n",
      "Saved: preprocessed\\uav0000222_03150_v_processed.csv with 7759 entries.\n",
      "\n",
      "Processing sequence: uav0000239_03720_v\n",
      "Saved: preprocessed\\uav0000239_03720_v_processed.csv with 6942 entries.\n",
      "\n",
      "Processing sequence: uav0000239_12336_v\n",
      "Saved: preprocessed\\uav0000239_12336_v_processed.csv with 5310 entries.\n",
      "\n",
      "Processing sequence: uav0000243_00001_v\n",
      "Saved: preprocessed\\uav0000243_00001_v_processed.csv with 10503 entries.\n",
      "\n",
      "Processing sequence: uav0000244_01440_v\n",
      "Saved: preprocessed\\uav0000244_01440_v_processed.csv with 16519 entries.\n",
      "\n",
      "Processing sequence: uav0000248_00001_v\n",
      "Saved: preprocessed\\uav0000248_00001_v_processed.csv with 13389 entries.\n",
      "\n",
      "Processing sequence: uav0000263_03289_v\n",
      "Saved: preprocessed\\uav0000263_03289_v_processed.csv with 2577 entries.\n",
      "\n",
      "Processing sequence: uav0000264_02760_v\n",
      "Saved: preprocessed\\uav0000264_02760_v_processed.csv with 6502 entries.\n",
      "\n",
      "Processing sequence: uav0000266_03598_v\n",
      "Saved: preprocessed\\uav0000266_03598_v_processed.csv with 1378 entries.\n",
      "\n",
      "Processing sequence: uav0000266_04830_v\n",
      "Saved: preprocessed\\uav0000266_04830_v_processed.csv with 358 entries.\n",
      "\n",
      "Processing sequence: uav0000270_00001_v\n",
      "Saved: preprocessed\\uav0000270_00001_v_processed.csv with 12109 entries.\n",
      "\n",
      "Processing sequence: uav0000273_00001_v\n",
      "Saved: preprocessed\\uav0000273_00001_v_processed.csv with 13023 entries.\n",
      "\n",
      "Processing sequence: uav0000278_00001_v\n",
      "Saved: preprocessed\\uav0000278_00001_v_processed.csv with 20082 entries.\n",
      "\n",
      "Processing sequence: uav0000279_00001_v\n",
      "Saved: preprocessed\\uav0000279_00001_v_processed.csv with 19959 entries.\n",
      "\n",
      "Processing sequence: uav0000281_00460_v\n",
      "Saved: preprocessed\\uav0000281_00460_v_processed.csv with 8406 entries.\n",
      "\n",
      "Processing sequence: uav0000288_00001_v\n",
      "Saved: preprocessed\\uav0000288_00001_v_processed.csv with 10634 entries.\n",
      "\n",
      "Processing sequence: uav0000289_00001_v\n",
      "Saved: preprocessed\\uav0000289_00001_v_processed.csv with 5687 entries.\n",
      "\n",
      "Processing sequence: uav0000289_06922_v\n",
      "Saved: preprocessed\\uav0000289_06922_v_processed.csv with 4204 entries.\n",
      "\n",
      "Processing sequence: uav0000295_02300_v\n",
      "Saved: preprocessed\\uav0000295_02300_v_processed.csv with 11160 entries.\n",
      "\n",
      "Processing sequence: uav0000300_00000_v\n",
      "Saved: preprocessed\\uav0000300_00000_v_processed.csv with 6685 entries.\n",
      "\n",
      "Processing sequence: uav0000307_00000_v\n",
      "Saved: preprocessed\\uav0000307_00000_v_processed.csv with 4321 entries.\n",
      "\n",
      "Processing sequence: uav0000308_00000_v\n",
      "Saved: preprocessed\\uav0000308_00000_v_processed.csv with 2206 entries.\n",
      "\n",
      "Processing sequence: uav0000308_01380_v\n",
      "Saved: preprocessed\\uav0000308_01380_v_processed.csv with 795 entries.\n",
      "\n",
      "Processing sequence: uav0000309_00000_v\n",
      "Saved: preprocessed\\uav0000309_00000_v_processed.csv with 4326 entries.\n",
      "\n",
      "Processing sequence: uav0000315_00000_v\n",
      "Saved: preprocessed\\uav0000315_00000_v_processed.csv with 8060 entries.\n",
      "\n",
      "Processing sequence: uav0000316_01288_v\n",
      "Saved: preprocessed\\uav0000316_01288_v_processed.csv with 1131 entries.\n",
      "\n",
      "Processing sequence: uav0000323_01173_v\n",
      "Saved: preprocessed\\uav0000323_01173_v_processed.csv with 9356 entries.\n",
      "\n",
      "Processing sequence: uav0000326_01035_v\n",
      "Saved: preprocessed\\uav0000326_01035_v_processed.csv with 11130 entries.\n",
      "\n",
      "Processing sequence: uav0000329_04715_v\n",
      "Saved: preprocessed\\uav0000329_04715_v_processed.csv with 3745 entries.\n",
      "\n",
      "Processing sequence: uav0000342_04692_v\n",
      "Saved: preprocessed\\uav0000342_04692_v_processed.csv with 5103 entries.\n",
      "\n",
      "Processing sequence: uav0000352_05980_v\n",
      "Saved: preprocessed\\uav0000352_05980_v_processed.csv with 5142 entries.\n",
      "\n",
      "Processing sequence: uav0000357_00920_v\n",
      "Saved: preprocessed\\uav0000357_00920_v_processed.csv with 9053 entries.\n",
      "\n",
      "Processing sequence: uav0000360_00001_v\n",
      "Saved: preprocessed\\uav0000360_00001_v_processed.csv with 7719 entries.\n",
      "\n",
      "Processing sequence: uav0000361_02323_v\n",
      "Saved: preprocessed\\uav0000361_02323_v_processed.csv with 6834 entries.\n",
      "\n",
      "Processing sequence: uav0000363_00001_v\n",
      "Saved: preprocessed\\uav0000363_00001_v_processed.csv with 2000 entries.\n",
      "\n",
      "Processing sequence: uav0000366_00001_v\n",
      "Saved: preprocessed\\uav0000366_00001_v_processed.csv with 8907 entries.\n",
      "\n",
      "Tracklet mapping saved: preprocessed\\trackid_to_tracklets.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Input directories\n",
    "ANNOTATIONS_DIR = \"D:\\\\ML_PROJECT\\\\ML_2025_GROUP_XYZ\\\\VisDrone2019-MOT-train\\\\annotations\"\n",
    "SEQUENCES_DIR   = \"D:\\\\ML_PROJECT\\\\ML_2025_GROUP_XYZ\\\\VisDrone2019-MOT-train\\\\sequences\"\n",
    "\n",
    "# Output directories\n",
    "PREPROCESSED_DIR = \"preprocessed\"\n",
    "os.makedirs(PREPROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Keep only these categories\n",
    "VALID_CATEGORIES = {4, 5, 6}\n",
    "\n",
    "# ID counters\n",
    "global_track_id_counter = 1\n",
    "tracklet_id_counter = 1\n",
    "\n",
    "# Mapping from global track ID to its tracklets\n",
    "trackid_to_tracklets = defaultdict(list)\n",
    "\n",
    "# For each sequence\n",
    "def process_sequence(seq_name):\n",
    "    global global_track_id_counter, tracklet_id_counter\n",
    "    \n",
    "    print(f\"\\nProcessing sequence: {seq_name}\")\n",
    "    \n",
    "    # Paths\n",
    "    image_folder = os.path.join(SEQUENCES_DIR, seq_name)\n",
    "    annot_path   = os.path.join(ANNOTATIONS_DIR, seq_name + \".txt\")\n",
    "    output_csv   = os.path.join(PREPROCESSED_DIR, f\"{seq_name}_processed.csv\")\n",
    "\n",
    "    if not os.path.exists(annot_path):\n",
    "        print(f\"Annotation missing: {seq_name}\")\n",
    "        return\n",
    "    \n",
    "    # Read annotations and group by object_id\n",
    "    annotations = defaultdict(list)\n",
    "    with open(annot_path, 'r') as f:\n",
    "        for line in f:\n",
    "            vals = list(map(int, line.strip().split(',')))\n",
    "            if len(vals) < 10:\n",
    "                continue\n",
    "            frame_id, obj_id, x, y, w, h, conf, cat, vis, _ = vals\n",
    "            if cat not in VALID_CATEGORIES:\n",
    "                continue\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "            annotations[obj_id].append((frame_id, x, y, w, h, cx, cy))\n",
    "\n",
    "    output_rows = []\n",
    "\n",
    "    for old_obj_id, data in annotations.items():\n",
    "        data.sort()  # Sort by frame_id\n",
    "        global_id = global_track_id_counter\n",
    "        global_track_id_counter += 1\n",
    "\n",
    "        # Introduce gaps randomly to simulate broken tracklets\n",
    "        i = 0\n",
    "        while i < len(data):\n",
    "            if np.random.rand() < 0.3 and len(data) - i > 60:  # Random gap\n",
    "                gap = np.random.randint(15, 60)\n",
    "                i += gap\n",
    "                continue\n",
    "\n",
    "            # Define a chunk\n",
    "            chunk = []\n",
    "            while i < len(data):\n",
    "                if np.random.rand() < 0.2 and len(chunk) > 10:\n",
    "                    break\n",
    "                chunk.append(data[i])\n",
    "                i += 1\n",
    "            \n",
    "            if not chunk:\n",
    "                continue\n",
    "\n",
    "            # Assign new tracklet ID\n",
    "            current_tracklet_id = tracklet_id_counter\n",
    "            tracklet_id_counter += 1\n",
    "            trackid_to_tracklets[global_id].append(current_tracklet_id)\n",
    "\n",
    "            for (frame_id, x, y, w, h, cx, cy) in chunk:\n",
    "                output_rows.append([\n",
    "                    seq_name, global_id, current_tracklet_id,\n",
    "                    frame_id, x, y, w, h, cx, cy\n",
    "                ])\n",
    "    \n",
    "    # Save the processed annotations\n",
    "    with open(output_csv, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"sequence\", \"global_track_id\", \"tracklet_id\", \"frame_id\",\n",
    "            \"x\", \"y\", \"w\", \"h\", \"cx\", \"cy\"\n",
    "        ])\n",
    "        writer.writerows(output_rows)\n",
    "    \n",
    "    print(f\"Saved: {output_csv} with {len(output_rows)} entries.\")\n",
    "\n",
    "# Process all sequences\n",
    "if __name__ == \"__main__\":\n",
    "    seq_list = sorted(os.listdir(ANNOTATIONS_DIR))\n",
    "    for filename in seq_list:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            seq_name = filename.replace(\".txt\", \"\")\n",
    "            process_sequence(seq_name)\n",
    "\n",
    "    # Save trackid to tracklet map\n",
    "    map_file = os.path.join(PREPROCESSED_DIR, \"trackid_to_tracklets.csv\")\n",
    "    with open(map_file, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"global_track_id\", \"tracklet_ids\"])\n",
    "        for gid, tlist in trackid_to_tracklets.items():\n",
    "            writer.writerow([gid, \" \".join(map(str, tlist))])\n",
    "    print(f\"\\nTracklet mapping saved: {map_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f675ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 6 empty files:\n",
      " - uav0000013_00000_v_processed.csv\n",
      " - uav0000013_01073_v_processed.csv\n",
      " - uav0000013_01392_v_processed.csv\n",
      " - uav0000020_00406_v_processed.csv\n",
      " - uav0000084_00000_v_processed.csv\n",
      " - uav0000099_02109_v_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "preprocessed_dir = \"preprocessed\"\n",
    "\n",
    "deleted_files = []\n",
    "\n",
    "for filename in os.listdir(preprocessed_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(preprocessed_dir, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            if df.empty:\n",
    "                os.remove(filepath)\n",
    "                deleted_files.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "print(f\"Deleted {len(deleted_files)} empty files:\")\n",
    "for file in deleted_files:\n",
    "    print(f\" - {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33917c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] trackid_to_tracklets.csv missing 'tracklet_id' column.\n",
      "🎯 uav0000071_03240_v_processed.csv: 1375 entries | 102 tracklets\n",
      "🎯 uav0000072_04488_v_processed.csv: 484 entries | 38 tracklets\n",
      "🎯 uav0000072_05448_v_processed.csv: 1120 entries | 85 tracklets\n",
      "🎯 uav0000072_06432_v_processed.csv: 855 entries | 71 tracklets\n",
      "🎯 uav0000076_00720_v_processed.csv: 2021 entries | 150 tracklets\n",
      "🎯 uav0000079_00480_v_processed.csv: 20 entries | 2 tracklets\n",
      "🎯 uav0000124_00944_v_processed.csv: 19553 entries | 1337 tracklets\n",
      "🎯 uav0000126_00001_v_processed.csv: 25276 entries | 1772 tracklets\n",
      "🎯 uav0000138_00000_v_processed.csv: 8866 entries | 631 tracklets\n",
      "🎯 uav0000140_01590_v_processed.csv: 9150 entries | 687 tracklets\n",
      "🎯 uav0000143_02250_v_processed.csv: 6108 entries | 440 tracklets\n",
      "🎯 uav0000145_00000_v_processed.csv: 1588 entries | 110 tracklets\n",
      "🎯 uav0000150_02310_v_processed.csv: 5268 entries | 373 tracklets\n",
      "🎯 uav0000218_00001_v_processed.csv: 829 entries | 66 tracklets\n",
      "🎯 uav0000222_03150_v_processed.csv: 7759 entries | 554 tracklets\n",
      "🎯 uav0000239_03720_v_processed.csv: 6942 entries | 512 tracklets\n",
      "🎯 uav0000239_12336_v_processed.csv: 5310 entries | 388 tracklets\n",
      "🎯 uav0000243_00001_v_processed.csv: 10503 entries | 787 tracklets\n",
      "🎯 uav0000244_01440_v_processed.csv: 16519 entries | 1192 tracklets\n",
      "🎯 uav0000248_00001_v_processed.csv: 13389 entries | 912 tracklets\n",
      "🎯 uav0000263_03289_v_processed.csv: 2577 entries | 194 tracklets\n",
      "🎯 uav0000264_02760_v_processed.csv: 6502 entries | 461 tracklets\n",
      "🎯 uav0000266_03598_v_processed.csv: 1378 entries | 100 tracklets\n",
      "🎯 uav0000266_04830_v_processed.csv: 358 entries | 24 tracklets\n",
      "🎯 uav0000270_00001_v_processed.csv: 12109 entries | 858 tracklets\n",
      "🎯 uav0000273_00001_v_processed.csv: 13023 entries | 914 tracklets\n",
      "🎯 uav0000278_00001_v_processed.csv: 20082 entries | 1422 tracklets\n",
      "🎯 uav0000279_00001_v_processed.csv: 19959 entries | 1401 tracklets\n",
      "🎯 uav0000281_00460_v_processed.csv: 8406 entries | 605 tracklets\n",
      "🎯 uav0000288_00001_v_processed.csv: 10634 entries | 767 tracklets\n",
      "🎯 uav0000289_00001_v_processed.csv: 5687 entries | 395 tracklets\n",
      "🎯 uav0000289_06922_v_processed.csv: 4204 entries | 325 tracklets\n",
      "🎯 uav0000295_02300_v_processed.csv: 11160 entries | 814 tracklets\n",
      "🎯 uav0000300_00000_v_processed.csv: 6685 entries | 486 tracklets\n",
      "🎯 uav0000307_00000_v_processed.csv: 4321 entries | 317 tracklets\n",
      "🎯 uav0000308_00000_v_processed.csv: 2206 entries | 161 tracklets\n",
      "🎯 uav0000308_01380_v_processed.csv: 795 entries | 61 tracklets\n",
      "🎯 uav0000309_00000_v_processed.csv: 4326 entries | 319 tracklets\n",
      "🎯 uav0000315_00000_v_processed.csv: 8060 entries | 558 tracklets\n",
      "🎯 uav0000316_01288_v_processed.csv: 1131 entries | 87 tracklets\n",
      "🎯 uav0000323_01173_v_processed.csv: 9356 entries | 653 tracklets\n",
      "🎯 uav0000326_01035_v_processed.csv: 11130 entries | 778 tracklets\n",
      "🎯 uav0000329_04715_v_processed.csv: 3745 entries | 267 tracklets\n",
      "🎯 uav0000342_04692_v_processed.csv: 5103 entries | 387 tracklets\n",
      "🎯 uav0000352_05980_v_processed.csv: 5142 entries | 373 tracklets\n",
      "🎯 uav0000357_00920_v_processed.csv: 9053 entries | 644 tracklets\n",
      "🎯 uav0000360_00001_v_processed.csv: 7719 entries | 552 tracklets\n",
      "🎯 uav0000361_02323_v_processed.csv: 6834 entries | 499 tracklets\n",
      "🎯 uav0000363_00001_v_processed.csv: 2000 entries | 147 tracklets\n",
      "🎯 uav0000366_00001_v_processed.csv: 8907 entries | 627 tracklets\n",
      "✅ All tracklets extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "preprocessed_dir = \"preprocessed\"\n",
    "tracklet_dir = \"tracklets\"\n",
    "os.makedirs(tracklet_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(preprocessed_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(preprocessed_dir, filename)\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"[SKIP] {filename} is empty.\")\n",
    "            continue\n",
    "\n",
    "        if 'tracklet_id' not in df.columns:\n",
    "            print(f\"[ERROR] {filename} missing 'tracklet_id' column.\")\n",
    "            continue\n",
    "\n",
    "        video_id = filename.replace(\"_processed.csv\", \"\")\n",
    "        unique_tracklets = df['tracklet_id'].unique()\n",
    "        print(f\"🎯 {filename}: {len(df)} entries | {len(unique_tracklets)} tracklets\")\n",
    "\n",
    "        for tid in unique_tracklets:\n",
    "            tracklet_df = df[df['tracklet_id'] == tid].sort_values(by=\"frame_id\")\n",
    "            if tracklet_df.empty:\n",
    "                print(f\"[WARN] Empty tracklet {tid} in {video_id}\")\n",
    "                continue\n",
    "\n",
    "            out_path = os.path.join(tracklet_dir, f\"{video_id}_tracklet{tid}.csv\")\n",
    "            tracklet_df.to_csv(out_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] {filename} -> {e}\")\n",
    "\n",
    "print(\"✅ All tracklets extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2d8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracklet generation and saving completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Input/output directories\n",
    "INPUT_DIR = 'preprocessed'  # Replace with your path\n",
    "OUTPUT_DIR = 'processed_tracklets'  # Replace with your path\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Define the range for skipping frames (between 15 to 60)\n",
    "MIN_SKIP = 15\n",
    "MAX_SKIP = 60\n",
    "\n",
    "# Process files in input directory\n",
    "for filename in os.listdir(INPUT_DIR):\n",
    "    path = os.path.join(INPUT_DIR, filename)\n",
    "    \n",
    "    # Read in the data from CSV\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # If empty or no 'global_track_id' column, skip file\n",
    "    if df.empty or 'global_track_id' not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # Extract the sequence name (from the file name, excluding extension)\n",
    "    sequence_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Iterate over unique global_track_id\n",
    "    for global_track_id in df['global_track_id'].unique():\n",
    "        # Get all frames corresponding to this global_track_id\n",
    "        track_data = df[df['global_track_id'] == global_track_id]\n",
    "        \n",
    "        # Sort by frame_id to ensure proper order\n",
    "        track_data = track_data.sort_values(by='frame_id')\n",
    "        \n",
    "        # Create tracklets by splitting the track into smaller segments\n",
    "        tracklet_id = 1\n",
    "        start_frame = 0\n",
    "        while start_frame < len(track_data):\n",
    "            # Determine the length of the current tracklet by skipping random frames\n",
    "            skip = random.randint(MIN_SKIP, MAX_SKIP)\n",
    "            end_frame = min(start_frame + skip, len(track_data))\n",
    "            \n",
    "            # Assign tracklet_id for the segment\n",
    "            track_data.loc[start_frame:end_frame-1, 'tracklet_id'] = tracklet_id\n",
    "            \n",
    "            # Move to the next tracklet\n",
    "            tracklet_id += 1\n",
    "            start_frame = end_frame\n",
    "        \n",
    "        # Save the processed track data with tracklet IDs to a new CSV\n",
    "        output_path = os.path.join(OUTPUT_DIR, f\"{sequence_name}_processed.csv\")\n",
    "        track_data.to_csv(output_path, index=False, mode='a', header=not os.path.exists(output_path))\n",
    "\n",
    "print(\"Tracklet generation and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222e379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['global_track_id', 'tracklet_ids'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  # Print column names to check for any discrepancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab8fccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] CSVs saved for uav0000013_00000_v.txt\n",
      "[✓] CSVs saved for uav0000013_01073_v.txt\n",
      "[✓] CSVs saved for uav0000013_01392_v.txt\n",
      "[✓] CSVs saved for uav0000020_00406_v.txt\n",
      "[✓] CSVs saved for uav0000071_03240_v.txt\n",
      "[✓] CSVs saved for uav0000072_04488_v.txt\n",
      "[✓] CSVs saved for uav0000072_05448_v.txt\n",
      "[✓] CSVs saved for uav0000072_06432_v.txt\n",
      "[✓] CSVs saved for uav0000076_00720_v.txt\n",
      "[✓] CSVs saved for uav0000079_00480_v.txt\n",
      "[✓] CSVs saved for uav0000084_00000_v.txt\n",
      "[✓] CSVs saved for uav0000099_02109_v.txt\n",
      "[✓] CSVs saved for uav0000124_00944_v.txt\n",
      "[✓] CSVs saved for uav0000126_00001_v.txt\n",
      "[✓] CSVs saved for uav0000138_00000_v.txt\n",
      "[✓] CSVs saved for uav0000140_01590_v.txt\n",
      "[✓] CSVs saved for uav0000143_02250_v.txt\n",
      "[✓] CSVs saved for uav0000145_00000_v.txt\n",
      "[✓] CSVs saved for uav0000150_02310_v.txt\n",
      "[✓] CSVs saved for uav0000218_00001_v.txt\n",
      "[✓] CSVs saved for uav0000222_03150_v.txt\n",
      "[✓] CSVs saved for uav0000239_03720_v.txt\n",
      "[✓] CSVs saved for uav0000239_12336_v.txt\n",
      "[✓] CSVs saved for uav0000243_00001_v.txt\n",
      "[✓] CSVs saved for uav0000244_01440_v.txt\n",
      "[✓] CSVs saved for uav0000248_00001_v.txt\n",
      "[✓] CSVs saved for uav0000263_03289_v.txt\n",
      "[✓] CSVs saved for uav0000264_02760_v.txt\n",
      "[✓] CSVs saved for uav0000266_03598_v.txt\n",
      "[✓] CSVs saved for uav0000266_04830_v.txt\n",
      "[✓] CSVs saved for uav0000270_00001_v.txt\n",
      "[✓] CSVs saved for uav0000273_00001_v.txt\n",
      "[✓] CSVs saved for uav0000278_00001_v.txt\n",
      "[✓] CSVs saved for uav0000279_00001_v.txt\n",
      "[✓] CSVs saved for uav0000281_00460_v.txt\n",
      "[✓] CSVs saved for uav0000288_00001_v.txt\n",
      "[✓] CSVs saved for uav0000289_00001_v.txt\n",
      "[✓] CSVs saved for uav0000289_06922_v.txt\n",
      "[✓] CSVs saved for uav0000295_02300_v.txt\n",
      "[✓] CSVs saved for uav0000300_00000_v.txt\n",
      "[✓] CSVs saved for uav0000307_00000_v.txt\n",
      "[✓] CSVs saved for uav0000308_00000_v.txt\n",
      "[✓] CSVs saved for uav0000308_01380_v.txt\n",
      "[✓] CSVs saved for uav0000309_00000_v.txt\n",
      "[✓] CSVs saved for uav0000315_00000_v.txt\n",
      "[✓] CSVs saved for uav0000316_01288_v.txt\n",
      "[✓] CSVs saved for uav0000323_01173_v.txt\n",
      "[✓] CSVs saved for uav0000326_01035_v.txt\n",
      "[✓] CSVs saved for uav0000329_04715_v.txt\n",
      "[✓] CSVs saved for uav0000342_04692_v.txt\n",
      "[✓] CSVs saved for uav0000352_05980_v.txt\n",
      "[✓] CSVs saved for uav0000357_00920_v.txt\n",
      "[✓] CSVs saved for uav0000360_00001_v.txt\n",
      "[✓] CSVs saved for uav0000361_02323_v.txt\n",
      "[✓] CSVs saved for uav0000363_00001_v.txt\n",
      "[✓] CSVs saved for uav0000366_00001_v.txt\n",
      "\n",
      "🔥 All annotation files converted to CSVs. Check 'processed_annotations' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Paths ===\n",
    "ROOT_DIR = r\"D:\\ML_PROJECT\\ML_2025_GROUP_XYZ\\VisDrone2019-MOT-train\"\n",
    "ANNOT_DIR = os.path.join(ROOT_DIR, \"annotations\")\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, \"processed_annotations\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === Settings ===\n",
    "VEHICLE_CATEGORIES = {4, 5, 6}\n",
    "MIN_TRACKLET_LENGTH = 5\n",
    "\n",
    "# === Helper Function ===\n",
    "def process_annotation_file(file_path, output_dir):\n",
    "    filename = os.path.basename(file_path)\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "\n",
    "    object_tracks = defaultdict(list)\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = list(map(int, line.strip().split(',')))\n",
    "            frame_id, obj_id, x, y, w, h, _, category, _, _ = parts\n",
    "            if category in VEHICLE_CATEGORIES:\n",
    "                object_tracks[obj_id].append((frame_id, x, y, w, h, category))\n",
    "\n",
    "    tracklet_id_counter = 0\n",
    "    tracklet_annotations = []\n",
    "    tracklet_mapping = []\n",
    "\n",
    "    for track_id, entries in object_tracks.items():\n",
    "        entries = sorted(entries, key=lambda e: e[0])\n",
    "        frames = [e[0] for e in entries]\n",
    "\n",
    "        cut_indices = []\n",
    "        i = 0\n",
    "        while i < len(frames):\n",
    "            cut_len = np.random.randint(15, 60)\n",
    "            cut_indices.append(i)\n",
    "            i += cut_len\n",
    "        cut_indices.append(len(frames))\n",
    "\n",
    "        for i in range(len(cut_indices) - 1):\n",
    "            start = cut_indices[i]\n",
    "            end = cut_indices[i + 1]\n",
    "            if end - start < MIN_TRACKLET_LENGTH:\n",
    "                continue\n",
    "\n",
    "            tracklet_id = tracklet_id_counter\n",
    "            tracklet_id_counter += 1\n",
    "            tracklet_mapping.append((track_id, tracklet_id))\n",
    "\n",
    "            for j in range(start, end):\n",
    "                f_id, x, y, w, h, cat = entries[j]\n",
    "                tracklet_annotations.append([f_id, tracklet_id, x, y, w, h, 1, cat, 1, 0])\n",
    "\n",
    "    tracklet_annotations.sort(key=lambda x: x[0])\n",
    "\n",
    "    filtered_csv = os.path.join(output_dir, f\"filtered_{basename}.csv\")\n",
    "    mapping_csv = os.path.join(output_dir, f\"mapping_{basename}.csv\")\n",
    "\n",
    "    with open(filtered_csv, \"w\", newline='') as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow([\"frame_id\", \"tracklet_id\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"category\", \"visibility\", \"unused\"])\n",
    "        writer.writerows(tracklet_annotations)\n",
    "\n",
    "    with open(mapping_csv, \"w\", newline='') as f_map:\n",
    "        writer = csv.writer(f_map)\n",
    "        writer.writerow([\"original_track_id\", \"new_tracklet_id\"])\n",
    "        writer.writerows(tracklet_mapping)\n",
    "\n",
    "    print(f\"[✓] CSVs saved for {filename}\")\n",
    "\n",
    "\n",
    "# === Run All Files ===\n",
    "all_files = [f for f in os.listdir(ANNOT_DIR) if f.endswith('.txt')]\n",
    "\n",
    "for fname in all_files:\n",
    "    full_path = os.path.join(ANNOT_DIR, fname)\n",
    "    process_annotation_file(full_path, OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n🔥 All annotation files converted to CSVs. Check 'processed_annotations' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41913cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
